# MNIST_classification

This was a task to create a HW that infers MNIST using a small model consisting of two convolution layers and one fully connected layer. It was done using a Pynq-z2 board, but there is a limit to the usage of bram to place all layers on the board at once. Therefore, a binary neural network was used that expresses all weights and activation values ​​as only -1 and 1 from the learning process. (MNIST is a small dataset, so even if you use bnn, you can maintain an accuracy of over 90%.) If -1 is mapped to 0 on the HW, multiplication can be implemented as XNOR and accumulative sum as popcount. I did all the parts related to writing the HLS code and bnn learning, FPGA excution. The bnn learning accuracy was stuck at 88%, but my teammate contributed to raising it to 93%. (Finding the optimal binarization threshold value, adding torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0))
